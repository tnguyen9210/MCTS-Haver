{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec74e067-4a28-4ea8-a9cc-2f42451e3be1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import random\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=2, suppress=True)\n",
    "\n",
    "import time\n",
    "import copy \n",
    "import multiprocess as mp\n",
    "\n",
    "import gym\n",
    "from env import FrozenLakeCustom, FrozenLakeSimulator\n",
    "\n",
    "from mcts_haver import run_mcts_trial\n",
    "from value_iteration import value_iteration\n",
    "\n",
    "from config import parse_args\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.FATAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7439dddd-4cdb-485d-a305-16d217b8781b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "# params\n",
    "args = parse_args()\n",
    "args[\"update_method\"] = \"haver\"\n",
    "args[\"rollout_method\"] = \"vit\"\n",
    "\n",
    "\n",
    "#\n",
    "env_id = \"FrozenLake-v1\"\n",
    "env = FrozenLakeCustom(\n",
    "    map_name=args[\"map_name\"], is_slippery=args[\"is_slippery\"],\n",
    "    render_mode=args[\"render_mode\"])\n",
    "\n",
    "simulator = FrozenLakeSimulator(env.P)\n",
    "\n",
    "V_vit, Q_vit = value_iteration(\n",
    "    simulator, args[\"gamma\"], args[\"vit_thres\"])\n",
    "# global Q_vit_g = Q_vit\n",
    "        \n",
    "for state in range(simulator.num_states):\n",
    "    logging.warning(f\"\\n-> state = {state}\")\n",
    "    logging.warning(f\"V[state] = {V_vit[state]:0.4f}\")\n",
    "    for action in range(simulator.num_actions):\n",
    "        logging.warning(f\"Q[state][action] = {Q_vit[state][action]:0.4f}\")\n",
    "    logging.warning(f\"best_action={np.argmax(Q_vit[state])}\")\n",
    "    \n",
    "manager = mp.Manager()\n",
    "ep_reward_list = manager.list()\n",
    "Q_mcts_list = manager.list()\n",
    "\n",
    "def run_trial(i_trial, Q_vit, args):\n",
    "\n",
    "    random.seed(10000+i_trial)\n",
    "    np.random.seed(10000+i_trial)\n",
    "\n",
    "#     env = FrozenLakeCustom(\n",
    "#         map_name=args[\"map_name\"], is_slippery=args[\"is_slippery\"],\n",
    "#         render_mode=args[\"render_mode\"])\n",
    "\n",
    "#     simulator = FrozenLakeSimulator(env.P)\n",
    "\n",
    "    Q_mcts, ep_reward = run_mcts_trial(env, simulator, Q_vit, i_trial, args)\n",
    "\n",
    "    ep_reward_list.append(ep_reward)\n",
    "    Q_mcts_list.append(Q_mcts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9d0cc51-788f-4160-82e6-30a1aea317fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_trials = 20\n",
      "mcts_max_its = 2000\n",
      "\n",
      "-> hparam_haver_var = 0.5\n",
      "hparam_ucb_scale = 20\n",
      "reward = -5.00 +/- 1.81\n",
      "it takes 35.3906\n",
      "hparam_ucb_scale = 22\n",
      "reward = -5.05 +/- 1.88\n",
      "it takes 40.1780\n",
      "hparam_ucb_scale = 24\n",
      "reward = -4.10 +/- 0.31\n",
      "it takes 27.3624\n",
      "hparam_ucb_scale = 26\n",
      "reward = -4.55 +/- 0.83\n",
      "it takes 32.5576\n",
      "hparam_ucb_scale = 28\n",
      "reward = -4.20 +/- 0.52\n",
      "it takes 29.4409\n",
      "hparam_ucb_scale = 30\n",
      "reward = -4.20 +/- 0.70\n",
      "it takes 29.1914\n",
      "hparam_ucb_scale = 32\n",
      "reward = -4.05 +/- 0.22\n",
      "it takes 28.1405\n",
      "hparam_ucb_scale = 34\n",
      "reward = -4.10 +/- 0.45\n",
      "it takes 28.5213\n",
      "hparam_ucb_scale = 36\n",
      "reward = -4.15 +/- 0.49\n",
      "it takes 28.0269\n",
      "hparam_ucb_scale = 38\n",
      "reward = -4.10 +/- 0.31\n",
      "it takes 28.0451\n",
      "\n",
      "-> hparam_haver_var = 1.0\n",
      "hparam_ucb_scale = 20\n",
      "reward = -5.00 +/- 1.41\n",
      "it takes 31.8442\n",
      "hparam_ucb_scale = 22\n",
      "reward = -4.50 +/- 1.24\n",
      "it takes 33.3400\n",
      "hparam_ucb_scale = 24\n",
      "reward = -4.65 +/- 0.93\n",
      "it takes 32.4996\n",
      "hparam_ucb_scale = 26\n",
      "reward = -4.20 +/- 0.41\n",
      "it takes 28.4754\n",
      "hparam_ucb_scale = 28\n",
      "reward = -4.35 +/- 0.59\n",
      "it takes 29.3696\n",
      "hparam_ucb_scale = 30\n",
      "reward = -4.10 +/- 0.45\n",
      "it takes 27.8125\n",
      "hparam_ucb_scale = 32\n",
      "reward = -4.15 +/- 0.37\n",
      "it takes 27.5834\n",
      "hparam_ucb_scale = 34\n",
      "reward = -4.10 +/- 0.31\n",
      "it takes 28.2954\n",
      "hparam_ucb_scale = 36\n",
      "reward = -4.05 +/- 0.22\n",
      "it takes 28.6134\n",
      "hparam_ucb_scale = 38\n",
      "reward = -4.10 +/- 0.31\n",
      "it takes 28.8606\n",
      "\n",
      "-> hparam_haver_var = 2.0\n",
      "hparam_ucb_scale = 20\n",
      "reward = -4.75 +/- 1.16\n",
      "it takes 31.2821\n",
      "hparam_ucb_scale = 22\n",
      "reward = -4.75 +/- 0.97\n",
      "it takes 32.2055\n",
      "hparam_ucb_scale = 24\n",
      "reward = -4.75 +/- 1.25\n",
      "it takes 29.7251\n",
      "hparam_ucb_scale = 26\n",
      "reward = -4.50 +/- 1.10\n",
      "it takes 32.8050\n",
      "hparam_ucb_scale = 28\n",
      "reward = -4.40 +/- 0.68\n",
      "it takes 29.3855\n",
      "hparam_ucb_scale = 30\n",
      "reward = -4.10 +/- 0.31\n",
      "it takes 27.6634\n",
      "hparam_ucb_scale = 32\n",
      "reward = -4.45 +/- 0.89\n",
      "it takes 31.3285\n",
      "hparam_ucb_scale = 34\n",
      "reward = -4.25 +/- 0.91\n",
      "it takes 28.4397\n",
      "hparam_ucb_scale = 36\n",
      "reward = -4.10 +/- 0.31\n",
      "it takes 29.5355\n",
      "hparam_ucb_scale = 38\n",
      "reward = -4.35 +/- 0.67\n",
      "it takes 30.9941\n",
      "\n",
      "-> hparam_haver_var = 0.1\n",
      "hparam_ucb_scale = 20\n",
      "reward = -4.75 +/- 1.02\n",
      "it takes 31.3424\n",
      "hparam_ucb_scale = 22\n",
      "reward = -4.55 +/- 1.19\n",
      "it takes 30.4355\n",
      "hparam_ucb_scale = 24\n",
      "reward = -4.20 +/- 0.62\n",
      "it takes 30.3740\n",
      "hparam_ucb_scale = 26\n",
      "reward = -4.05 +/- 0.22\n",
      "it takes 28.5130\n",
      "hparam_ucb_scale = 28\n",
      "reward = -4.45 +/- 0.89\n",
      "it takes 31.5149\n",
      "hparam_ucb_scale = 30\n",
      "reward = -4.00 +/- 0.00\n",
      "it takes 28.0774\n",
      "hparam_ucb_scale = 32\n",
      "reward = -4.05 +/- 0.22\n",
      "it takes 28.6174\n",
      "hparam_ucb_scale = 34\n",
      "reward = -4.10 +/- 0.45\n",
      "it takes 27.8277\n",
      "hparam_ucb_scale = 36\n",
      "reward = -4.20 +/- 0.62\n",
      "it takes 28.6264\n",
      "hparam_ucb_scale = 38\n",
      "reward = -4.05 +/- 0.22\n",
      "it takes 29.5031\n"
     ]
    }
   ],
   "source": [
    "print(f\"num_trials = {args['num_trials']}\")\n",
    "print(f\"mcts_max_its = {args['mcts_max_iterations']}\")\n",
    "\n",
    "Q_mcts_dict = defaultdict()\n",
    "\n",
    "hparam_ucb_scale_ary = np.arange(20, 40, 2)\n",
    "\n",
    "hparam_haver_var_ary = np.arange(0.0, 2, 0.5)\n",
    "# hparam_haver_var_ary = [0.0001]\n",
    "hparam_haver_var_ary = [0.5, 1.0, 2.0, 0.1]\n",
    "best_param = None\n",
    "max_reward_mean = -np.inf\n",
    "for hparam_haver_var in hparam_haver_var_ary:\n",
    "    print(f\"\\n-> hparam_haver_var = {hparam_haver_var}\")\n",
    "    args[\"hparam_haver_var\"] = hparam_haver_var\n",
    "    for hparam_ucb_scale in hparam_ucb_scale_ary:\n",
    "        print(f\"hparam_ucb_scale = {hparam_ucb_scale}\")\n",
    "        args[\"hparam_ucb_scale\"] = hparam_ucb_scale\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        pool = mp.Pool()\n",
    "        pool.starmap(run_trial, [(i, Q_vit, args) for i in range(args[\"num_trials\"])])\n",
    "\n",
    "        reward_mean = np.mean(ep_reward_list)\n",
    "        reward_std = np.std(ep_reward_list, ddof=1)\n",
    "        print(f\"reward = {reward_mean:.2f} +/- {reward_std:.2f}\")\n",
    "\n",
    "        # Q_mcts_dict[f\"{hparam_haver_var}\"] = copy.deepcopy(Q_mcts_list)\n",
    "\n",
    "        if reward_mean > max_reward_mean:\n",
    "            max_reward_mean = reward_mean \n",
    "            best_param = hparam_haver_var\n",
    "\n",
    "        ep_reward_list[:] = []\n",
    "        Q_mcts_list[:] = []\n",
    "\n",
    "        end_time = time.time()\n",
    "        print(f\"it takes {end_time-start_time:0.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74d9d773-a10f-45bf-a513-9f8661c58c01",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'0.1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4179695/2521691269.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mQ_mcts_avg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimulator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi_trial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ_mcts\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQ_mcts_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf\"{best_param}\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimulator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mQ_mcts_avg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi_trial\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mQ_mcts_avg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi_trial\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mQ_mcts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '0.1'"
     ]
    }
   ],
   "source": [
    "Q_mcts_avg = defaultdict(lambda: np.zeros(simulator.num_actions))\n",
    "for i_trial, Q_mcts in enumerate(Q_mcts_dict[f\"{best_param}\"]):\n",
    "    for s in range(simulator.num_states):\n",
    "        Q_mcts_avg[s] = (1-1/(i_trial+1))*Q_mcts_avg[s] + 1/(i_trial+1)*Q_mcts[s]\n",
    "    \n",
    "for state in range(simulator.num_states):\n",
    "    print(f\"\\n-> state = {state}\")\n",
    "    print(f\"V[state] = {np.max(Q_mcts_avg[state]):0.4f} | {np.max(Q_vit[state]):0.4f}\")\n",
    "    for action in range(simulator.num_actions):\n",
    "        print(f\"Q[state][action] = {Q_mcts_avg[state][action]:0.4f} | {Q_vit[state][action]:0.4f}\")\n",
    "    print(f\"best_action = {np.argmax(Q_mcts_avg[state])} | {np.argmax(Q_vit[state])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
