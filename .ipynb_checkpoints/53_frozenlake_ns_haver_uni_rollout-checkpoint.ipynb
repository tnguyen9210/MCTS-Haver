{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec74e067-4a28-4ea8-a9cc-2f42451e3be1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import random\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=2, suppress=True)\n",
    "\n",
    "import time\n",
    "import copy \n",
    "import multiprocess as mp\n",
    "\n",
    "import gym\n",
    "from env import FrozenLakeCustom, FrozenLakeSimulator\n",
    "\n",
    "from mcts_haver import run_mcts_trial\n",
    "from value_iteration import value_iteration\n",
    "\n",
    "from config import parse_args\n",
    "from utils import MultiProcess\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.FATAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7439dddd-4cdb-485d-a305-16d217b8781b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "# params\n",
    "args = parse_args()\n",
    "\n",
    "#\n",
    "env_id = \"FrozenLake-v1\"\n",
    "env = FrozenLakeCustom(\n",
    "    map_name=args[\"map_name\"], is_slippery=args[\"is_slippery\"],\n",
    "    render_mode=args[\"render_mode\"])\n",
    "\n",
    "simulator = FrozenLakeSimulator(env.P)\n",
    "\n",
    "V_vit, Q_vit = value_iteration(\n",
    "    simulator, args[\"gamma\"], args[\"vit_thres\"])\n",
    "# global Q_vit_g = Q_vit\n",
    "        \n",
    "for state in range(simulator.num_states):\n",
    "    logging.warning(f\"\\n-> state = {state}\")\n",
    "    logging.warning(f\"V[state] = {V_vit[state]:0.4f}\")\n",
    "    for action in range(simulator.num_actions):\n",
    "        logging.warning(f\"Q[state][action] = {Q_vit[state][action]:0.4f}\")\n",
    "    logging.warning(f\"best_action={np.argmax(Q_vit[state])}\")\n",
    "    \n",
    "manager = mp.Manager()\n",
    "ep_reward_list = manager.list()\n",
    "Q_mcts_list = manager.list()\n",
    "\n",
    "def run_trial(i_trial, Q_vit, args):\n",
    "\n",
    "    random.seed(10000+i_trial)\n",
    "    np.random.seed(10000+i_trial)\n",
    "\n",
    "    env = FrozenLakeCustom(\n",
    "        map_name=args[\"map_name\"], is_slippery=args[\"is_slippery\"],\n",
    "        render_mode=args[\"render_mode\"])\n",
    "\n",
    "    simulator = FrozenLakeSimulator(env.P)\n",
    "\n",
    "    Q_mcts, ep_reward = run_mcts_trial(env, simulator, Q_vit, i_trial, args)\n",
    "\n",
    "    ep_reward_list.append(ep_reward)\n",
    "    Q_mcts_list.append(Q_mcts)\n",
    "    return ep_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9d0cc51-788f-4160-82e6-30a1aea317fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_trials = 500\n",
      "\n",
      "-> num_trajectories = 200\n",
      "\n",
      "-> hparam_ucb_scale = 1\n",
      "reward = -100.91 ± 0.19\n",
      "reward = -100.90 ± 0.19\n",
      "reward = -100.53 ± 0.34\n",
      "reward = -100.56 ± 0.34\n",
      "reward = -100.57 ± 0.34\n",
      "reward = -100.36 ± 0.39\n",
      "reward = -100.75 ± 0.28\n",
      "reward = -100.75 ± 0.28\n",
      "max_reward = -100.36 ± 0.39\n",
      "best_param = 32\n",
      "\n",
      "-> hparam_ucb_scale = 2\n",
      "reward = -99.21 ± 0.60\n",
      "reward = -99.39 ± 0.58\n",
      "reward = -100.17 ± 0.43\n",
      "reward = -100.16 ± 0.43\n",
      "reward = -100.37 ± 0.39\n",
      "reward = -99.78 ± 0.51\n",
      "reward = -100.16 ± 0.43\n",
      "reward = -100.36 ± 0.39\n",
      "max_reward = -99.21 ± 0.60\n",
      "best_param = 1\n",
      "\n",
      "-> hparam_ucb_scale = 4\n",
      "reward = -88.82 ± 1.45\n",
      "reward = -88.66 ± 1.45\n",
      "reward = -89.76 ± 1.39\n",
      "reward = -92.27 ± 1.25\n",
      "reward = -94.59 ± 1.09\n",
      "reward = -93.40 ± 1.18\n",
      "reward = -93.62 ± 1.16\n",
      "reward = -93.43 ± 1.17\n",
      "max_reward = -88.66 ± 1.45\n",
      "best_param = 2\n",
      "\n",
      "-> hparam_ucb_scale = 8\n",
      "reward = -67.10 ± 2.07\n",
      "reward = -68.30 ± 2.05\n",
      "reward = -65.04 ± 2.10\n",
      "reward = -72.36 ± 1.98\n",
      "reward = -76.37 ± 1.89\n",
      "reward = -73.70 ± 1.95\n",
      "reward = -78.77 ± 1.82\n",
      "reward = -78.76 ± 1.82\n",
      "max_reward = -65.04 ± 2.10\n",
      "best_param = 4\n",
      "\n",
      "-> hparam_ucb_scale = 16\n",
      "reward = -41.75 ± 2.11\n",
      "reward = -43.82 ± 2.13\n",
      "reward = -46.34 ± 2.15\n",
      "reward = -44.41 ± 2.13\n",
      "reward = -50.10 ± 2.16\n",
      "reward = -54.30 ± 2.16\n",
      "reward = -62.15 ± 2.12\n",
      "reward = -59.93 ± 2.14\n",
      "max_reward = -41.75 ± 2.11\n",
      "best_param = 1\n",
      "\n",
      "-> hparam_ucb_scale = 32\n",
      "reward = -28.84 ± 1.89\n",
      "reward = -30.98 ± 1.94\n",
      "reward = -32.48 ± 1.97\n",
      "reward = -31.11 ± 1.94\n",
      "reward = -36.98 ± 2.05\n",
      "reward = -38.92 ± 2.08\n",
      "reward = -49.46 ± 2.16\n",
      "reward = -43.51 ± 2.12\n",
      "max_reward = -28.84 ± 1.89\n",
      "best_param = 1\n",
      "\n",
      "-> hparam_ucb_scale = 64\n",
      "reward = -26.28 ± 1.82\n",
      "reward = -27.24 ± 1.85\n",
      "reward = -28.79 ± 1.89\n",
      "reward = -30.51 ± 1.93\n",
      "reward = -31.06 ± 1.95\n",
      "reward = -36.74 ± 2.05\n",
      "reward = -50.71 ± 2.17\n",
      "reward = -63.21 ± 2.12\n",
      "max_reward = -26.28 ± 1.82\n",
      "best_param = 1\n",
      "\n",
      "-> hparam_ucb_scale = 128\n",
      "reward = -29.98 ± 1.92\n",
      "reward = -23.19 ± 1.72\n",
      "reward = -29.79 ± 1.92\n",
      "reward = -28.65 ± 1.89\n",
      "reward = -35.04 ± 2.02\n",
      "reward = -38.73 ± 2.08\n",
      "reward = -56.12 ± 2.16\n",
      "reward = -69.01 ± 2.04\n",
      "max_reward = -23.19 ± 1.72\n",
      "best_param = 2\n",
      "it takes 1825.7767\n"
     ]
    }
   ],
   "source": [
    "args[\"update_method\"] = \"haver\"\n",
    "args[\"rollout_method\"] = \"\"\n",
    "\n",
    "print(f\"num_trials = {args['num_trials']}\")\n",
    "# print(f\"mcts_num_trajectories = {args['mcts_num_trajectories']}\")\n",
    "\n",
    "\n",
    "hparam_ucb_scale_list = np.arange(10, 100, 10)\n",
    "hparam_ucb_scale_list = [1, 2, 4, 8, 16, 32, 64, 128]\n",
    "# hparam_ucb_scale_list = [2**i for i in range(1, 9)]\n",
    "args[\"hparam_ucb_scale\"] = 64\n",
    "\n",
    "hparam_haver_std_list = np.arange(10, 100, 10)\n",
    "hparam_haver_std_list = [1, 2, 4, 8, 16, 32, 64, 128]\n",
    "# hparam_haver_std_list = [2**i for i in range(1, 9)]\n",
    "\n",
    "\n",
    "# num_trajectories_list = [200, 500, 1000, 1500, 2000, 2500, 3000]\n",
    "num_trajectories_list = [200]\n",
    "# num_trajectories_list = [2]\n",
    "best_param_list = []\n",
    "max_reward_mean_list = []\n",
    "res_text1 = \"\"\n",
    "res_text2 = \"\"\n",
    "for num_trajectories in num_trajectories_list:\n",
    "    print(f\"\\n-> num_trajectories = {num_trajectories}\")\n",
    "    args[\"mcts_num_trajectories\"] = num_trajectories\n",
    "    \n",
    "    # best_param = None\n",
    "    # max_reward_mean = -np.inf\n",
    "    start_time = time.time()\n",
    "    res_text1 += f\"{num_trajectories} \"\n",
    "    res_text2 += f\"{num_trajectories} \"\n",
    "    for hparam_ucb_scale in hparam_ucb_scale_list: \n",
    "        \n",
    "        args[\"hparam_ucb_scale\"] = hparam_ucb_scale\n",
    "        print(f\"\\n-> hparam_ucb_scale = {hparam_ucb_scale}\")\n",
    "        \n",
    "        max_reward_mean = -np.inf\n",
    "        best_param = None\n",
    "        max_reward_error = None\n",
    "        \n",
    "        for hparam_haver_std in hparam_haver_std_list:\n",
    "            # start_time = time.time()\n",
    "\n",
    "            args[\"hparam_haver_var\"] = hparam_haver_std**2\n",
    "            # print(f\"hparam_haver_var = {args['hparam_haver_var']}\")\n",
    "            # print(f\"hparam_ucb_scale = {args['hparam_ucb_scale']}\")\n",
    "\n",
    "            pool = mp.Pool()\n",
    "            pool.starmap(run_trial, [(i, Q_vit, args) for i in range(args[\"num_trials\"])])\n",
    "\n",
    "            reward_mean = np.mean(ep_reward_list)\n",
    "            reward_std = np.std(ep_reward_list, ddof=1) if len(ep_reward_list) > 1 else 0\n",
    "            reward_error = reward_std/np.sqrt(args[\"num_trials\"])\n",
    "            # if hparam_haver_std <= 8:\n",
    "            #     res_text1 += f\"& {reward_mean:0.2f} (\\u00B1{reward_error:0.2f}) \"\n",
    "            # else:\n",
    "            #     res_text2 += f\"& {reward_mean:0.2f} (\\u00B1{reward_error:0.2f}) \"\n",
    "            print(f\"reward = {reward_mean:0.2f} \\u00B1 {reward_error:0.2f}\")\n",
    "\n",
    "            if reward_mean > max_reward_mean:\n",
    "                max_reward_mean = reward_mean \n",
    "                max_reward_error = reward_error\n",
    "                best_param = hparam_haver_std\n",
    "                \n",
    "            ep_reward_list[:] = []\n",
    "            Q_mcts_list[:] = []\n",
    "\n",
    "            end_time = time.time()\n",
    "            # print(f\"it takes {end_time-start_time:0.4f}\")\n",
    "        \n",
    "        if hparam_ucb_scale <= 8:\n",
    "            res_text1 += f\"& {max_reward_mean:0.2f} (\\u00B1{max_reward_error:0.2f}) \"\n",
    "        else:\n",
    "            res_text2 += f\"& {max_reward_mean:0.2f} (\\u00B1{max_reward_error:0.2f}) \"\n",
    "            \n",
    "        print(f\"max_reward = {max_reward_mean:0.2f} \\u00B1 {max_reward_error:0.2f}\")\n",
    "        print(f\"best_param = {best_param}\")\n",
    "            \n",
    "    res_text1 += \"\\\\\\\\ \\n \\hline \\n\"\n",
    "    res_text2 += \"\\\\\\\\ \\n \\hline \\n\"\n",
    "\n",
    "    # print(f\"max_reward_mean = {max_reward_mean:0.2f}\")\n",
    "    print(f\"it takes {end_time-start_time:0.4f}\")\n",
    "\n",
    "    max_reward_mean_list.append(max_reward_mean)\n",
    "    best_param_list.append(best_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62dda670-a657-4df7-8c01-56ff279c8c33",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 & -100.36 (±0.39) & -99.21 (±0.60) & -88.66 (±1.45) & -65.04 (±2.10) \\\\ \n",
      " \\hline \n",
      "\n",
      "200 & -41.75 (±2.11) & -28.84 (±1.89) & -26.28 (±1.82) & -23.19 (±1.72) \\\\ \n",
      " \\hline \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(res_text1)\n",
    "print(res_text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c5115f8-44e4-4f14-b040-ffc7ee69a1e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_trials = 500\n",
      "\n",
      "-> num_trajectories = 500\n",
      "\n",
      "-> hparam_ucb_scale = 1\n",
      "reward = -100.70 ± 0.27\n",
      "reward = -100.89 ± 0.19\n",
      "reward = -100.88 ± 0.19\n",
      "reward = -100.91 ± 0.19\n",
      "reward = -100.71 ± 0.27\n",
      "reward = -100.91 ± 0.19\n",
      "reward = -100.90 ± 0.19\n",
      "reward = -100.90 ± 0.19\n",
      "max_reward = -100.70 ± 0.27\n",
      "best_param = 1\n",
      "\n",
      "-> hparam_ucb_scale = 2\n",
      "reward = -97.82 ± 0.79\n",
      "reward = -97.60 ± 0.81\n",
      "reward = -100.30 ± 0.39\n",
      "reward = -98.98 ± 0.63\n",
      "reward = -99.60 ± 0.54\n",
      "reward = -99.61 ± 0.54\n",
      "reward = -99.77 ± 0.51\n",
      "reward = -99.97 ± 0.47\n",
      "max_reward = -97.60 ± 0.81\n",
      "best_param = 2\n",
      "\n",
      "-> hparam_ucb_scale = 4\n",
      "reward = -83.70 ± 1.67\n",
      "reward = -81.61 ± 1.74\n",
      "reward = -86.45 ± 1.55\n",
      "reward = -86.08 ± 1.57\n",
      "reward = -88.62 ± 1.45\n",
      "reward = -89.38 ± 1.42\n",
      "reward = -90.36 ± 1.36\n",
      "reward = -90.56 ± 1.35\n",
      "max_reward = -81.61 ± 1.74\n",
      "best_param = 2\n",
      "\n",
      "-> hparam_ucb_scale = 8\n",
      "reward = -44.66 ± 2.13\n",
      "reward = -44.81 ± 2.13\n",
      "reward = -46.99 ± 2.15\n",
      "reward = -49.60 ± 2.16\n",
      "reward = -50.65 ± 2.16\n",
      "reward = -53.21 ± 2.16\n",
      "reward = -54.70 ± 2.16\n",
      "reward = -55.21 ± 2.16\n",
      "max_reward = -44.66 ± 2.13\n",
      "best_param = 1\n",
      "\n",
      "-> hparam_ucb_scale = 16\n",
      "reward = -29.04 ± 1.89\n",
      "reward = -30.00 ± 1.91\n",
      "reward = -28.26 ± 1.87\n",
      "reward = -28.86 ± 1.89\n",
      "reward = -33.96 ± 1.99\n",
      "reward = -31.63 ± 1.95\n",
      "reward = -33.86 ± 1.99\n",
      "reward = -32.96 ± 1.97\n",
      "max_reward = -28.26 ± 1.87\n",
      "best_param = 4\n",
      "\n",
      "-> hparam_ucb_scale = 32\n",
      "reward = -17.65 ± 1.51\n",
      "reward = -17.85 ± 1.51\n",
      "reward = -21.16 ± 1.65\n",
      "reward = -18.84 ± 1.56\n",
      "reward = -20.60 ± 1.63\n",
      "reward = -23.11 ± 1.72\n",
      "reward = -26.63 ± 1.82\n",
      "reward = -28.34 ± 1.87\n",
      "max_reward = -17.65 ± 1.51\n",
      "best_param = 1\n",
      "\n",
      "-> hparam_ucb_scale = 64\n",
      "reward = -18.75 ± 1.56\n",
      "reward = -19.52 ± 1.59\n",
      "reward = -21.85 ± 1.68\n",
      "reward = -19.53 ± 1.59\n",
      "reward = -21.28 ± 1.66\n",
      "reward = -21.09 ± 1.65\n",
      "reward = -25.35 ± 1.80\n",
      "reward = -27.49 ± 1.86\n",
      "max_reward = -18.75 ± 1.56\n",
      "best_param = 1\n",
      "\n",
      "-> hparam_ucb_scale = 128\n",
      "reward = -15.65 ± 1.41\n",
      "reward = -16.42 ± 1.45\n",
      "reward = -17.60 ± 1.51\n",
      "reward = -17.78 ± 1.52\n",
      "reward = -21.67 ± 1.68\n",
      "reward = -23.80 ± 1.75\n",
      "reward = -32.54 ± 1.98\n",
      "reward = -41.06 ± 2.11\n",
      "max_reward = -15.65 ± 1.41\n",
      "best_param = 1\n",
      "it takes 5175.3079\n"
     ]
    }
   ],
   "source": [
    "args[\"update_method\"] = \"haver\"\n",
    "args[\"rollout_method\"] = \"\"\n",
    "\n",
    "print(f\"num_trials = {args['num_trials']}\")\n",
    "# print(f\"mcts_num_trajectories = {args['mcts_num_trajectories']}\")\n",
    "\n",
    "\n",
    "hparam_ucb_scale_list = np.arange(10, 100, 10)\n",
    "hparam_ucb_scale_list = [1, 2, 4, 8, 16, 32, 64, 128]\n",
    "# hparam_ucb_scale_list = [2**i for i in range(1, 9)]\n",
    "args[\"hparam_ucb_scale\"] = 64\n",
    "\n",
    "hparam_haver_std_list = np.arange(10, 100, 10)\n",
    "hparam_haver_std_list = [1, 2, 4, 8, 16, 32, 64, 128]\n",
    "# hparam_haver_std_list = [2**i for i in range(1, 9)]\n",
    "\n",
    "\n",
    "# num_trajectories_list = [200, 500, 1000, 1500, 2000, 2500, 3000]\n",
    "num_trajectories_list = [500]\n",
    "# num_trajectories_list = [2]\n",
    "best_param_list = []\n",
    "max_reward_mean_list = []\n",
    "res_text1 = \"\"\n",
    "res_text2 = \"\"\n",
    "for num_trajectories in num_trajectories_list:\n",
    "    print(f\"\\n-> num_trajectories = {num_trajectories}\")\n",
    "    args[\"mcts_num_trajectories\"] = num_trajectories\n",
    "    \n",
    "    # best_param = None\n",
    "    # max_reward_mean = -np.inf\n",
    "    start_time = time.time()\n",
    "    res_text1 += f\"{num_trajectories} \"\n",
    "    res_text2 += f\"{num_trajectories} \"\n",
    "    for hparam_ucb_scale in hparam_ucb_scale_list: \n",
    "        \n",
    "        args[\"hparam_ucb_scale\"] = hparam_ucb_scale\n",
    "        print(f\"\\n-> hparam_ucb_scale = {hparam_ucb_scale}\")\n",
    "        \n",
    "        max_reward_mean = -np.inf\n",
    "        best_param = None\n",
    "        max_reward_error = None\n",
    "        \n",
    "        for hparam_haver_std in hparam_haver_std_list:\n",
    "            # start_time = time.time()\n",
    "\n",
    "            args[\"hparam_haver_var\"] = hparam_haver_std**2\n",
    "            # print(f\"hparam_haver_var = {args['hparam_haver_var']}\")\n",
    "            # print(f\"hparam_ucb_scale = {args['hparam_ucb_scale']}\")\n",
    "\n",
    "            pool = mp.Pool()\n",
    "            pool.starmap(run_trial, [(i, Q_vit, args) for i in range(args[\"num_trials\"])])\n",
    "\n",
    "            reward_mean = np.mean(ep_reward_list)\n",
    "            reward_std = np.std(ep_reward_list, ddof=1) if len(ep_reward_list) > 1 else 0\n",
    "            reward_error = reward_std/np.sqrt(args[\"num_trials\"])\n",
    "            # if hparam_haver_std <= 8:\n",
    "            #     res_text1 += f\"& {reward_mean:0.2f} (\\u00B1{reward_error:0.2f}) \"\n",
    "            # else:\n",
    "            #     res_text2 += f\"& {reward_mean:0.2f} (\\u00B1{reward_error:0.2f}) \"\n",
    "            print(f\"reward = {reward_mean:0.2f} \\u00B1 {reward_error:0.2f}\")\n",
    "\n",
    "            if reward_mean > max_reward_mean:\n",
    "                max_reward_mean = reward_mean \n",
    "                max_reward_error = reward_error\n",
    "                best_param = hparam_haver_std\n",
    "                \n",
    "            ep_reward_list[:] = []\n",
    "            Q_mcts_list[:] = []\n",
    "\n",
    "            end_time = time.time()\n",
    "            # print(f\"it takes {end_time-start_time:0.4f}\")\n",
    "        \n",
    "        if hparam_ucb_scale <= 8:\n",
    "            res_text1 += f\"& {max_reward_mean:0.2f} (\\u00B1{max_reward_error:0.2f}) \"\n",
    "        else:\n",
    "            res_text2 += f\"& {max_reward_mean:0.2f} (\\u00B1{max_reward_error:0.2f}) \"\n",
    "            \n",
    "        print(f\"max_reward = {max_reward_mean:0.2f} \\u00B1 {max_reward_error:0.2f}\")\n",
    "        print(f\"best_param = {best_param}\")\n",
    "            \n",
    "    res_text1 += \"\\\\\\\\ \\n \\hline \\n\"\n",
    "    res_text2 += \"\\\\\\\\ \\n \\hline \\n\"\n",
    "\n",
    "    # print(f\"max_reward_mean = {max_reward_mean:0.2f}\")\n",
    "    print(f\"it takes {end_time-start_time:0.4f}\")\n",
    "\n",
    "    max_reward_mean_list.append(max_reward_mean)\n",
    "    best_param_list.append(best_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9880dd5f-0ada-4033-b757-a2e120fb6ebf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 & -100.70 (±0.27) & -97.60 (±0.81) & -81.61 (±1.74) & -44.66 (±2.13) \\\\ \n",
      " \\hline \n",
      "\n",
      "500 & -28.26 (±1.87) & -17.65 (±1.51) & -18.75 (±1.56) & -15.65 (±1.41) \\\\ \n",
      " \\hline \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(res_text1)\n",
    "print(res_text2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
